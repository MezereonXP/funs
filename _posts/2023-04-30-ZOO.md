---
title: "暴力的黑盒对抗样本攻击 -- ZOO"
date: 2023-04-30 00:00:00 +0800
categories: [对抗样本]
tags: [对抗样本, 黑盒] 
math: true
toc: true
---


### 介绍

这次来介绍一篇CCS Workshop 2017的工作，"**ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models**"



![对抗攻击](https://mezereon-upic.oss-cn-shanghai.aliyuncs.com/uPic/image-20210406202132938.png)

这是一个黑盒的对抗样本攻击，如上图所示，攻击者只能进行输入，并且获得置信度的输出，不能对模型进行反向传播。

> 有关于白盒的对抗样本攻击，可以查看我这篇[文章](https://mezereonxp.fun/2023/04/28/adv-attacks.html)



不能反向传播，会导致对抗样本难以生成。那么怎么进行攻击呢，有一些工作的思路是训练一个替代模型（substitute model）来进行攻击。

> 替代模型是指利用类似分布的数据集，或者利用多次输入输出的结果，训练一个新的模型，并在新的模型上进行反向传播，进而得到一个对抗样本。



### 强行计算梯度



正如之前所说，没办法进行反向传播，梯度都没办法直接计算。

那么该工作便强行计算了一个伪梯度，我们来看看细节

首先我们先对输入 $x$ 进行一个扰动 $x = x + h\cdot e$

其中 $h = 0.0001$ 是一个常量值，$e$ 是一个标准单位向量，你可以理解为某一位为1其余都是0的向量。

我们记模型的输出为 $f(x)$ ，那么利用对称差分，可以得到一个估计梯度值
$$\tilde{g} = \frac{\partial f(x)}{\partial x} \simeq \frac{f(x+h\cdot e) - f(x-h\cdot e)}{2h}$$
同时，我们可以估计出二阶的梯度值
$$\tilde{h} = \frac{\partial^2 f(x)}{\partial x^2} \simeq \frac{f(x+h\cdot e) - 2f(x) + f(x-h\cdot e)}{h^2}$$


有了这两个梯度估计值，就可以直接对 $x$ 进行梯度下降优化了。比如牛顿法，那么则是
$$x = x - \eta \frac{\tilde{g}}{\tilde{h}}$$
其中 $\eta$ 是学习率

同理可以得到Adam的过程，这里不多赘述。



![algorithm-Newton](https://mezereon-upic.oss-cn-shanghai.aliyuncs.com/uPic/image-20210406202800259.png)

**如上图所示，算法会迭代数次，在每一次迭代的时候，随机选取一个像素位置，添加扰动并计算出梯度，多次迭代之后得到结果。**



### 结果分析

![cifar and mnist](https://mezereon-upic.oss-cn-shanghai.aliyuncs.com/uPic/image-20210406202427378.png)



作者在手写数据集MNIST和CIFAR10上进行测试，和白盒攻击C&W，以及替代模型方法进行了对比。

**从时间上看，黑盒攻击要更加花费时间，成功率也会有所下降**