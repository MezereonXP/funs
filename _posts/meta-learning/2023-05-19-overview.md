---
title: "Meta Learning简介"
date: 2023-05-19 13:52:00 +0800
math: true
categories: [元学习]
tags: [元学习]
---



先来回顾一下，传统的机器学习或者说深度学习的流程：

1. 确定训练和测试数据集
2. 确定模型结构
3. 初始化模型参数（通常是一些惯用的随机分布）
4. 初始化优化器类型和参数
5. 进行训练，直到收敛



Meta Learning的目的是去学习一些在步骤2，3，4的参数，我们称之为**元知识(meta- knowledge)**

不妨对其进行形式化

假设数据集为 $D = \{(x_1,y_1),...,(x_N,y_N)\}$ 其中 $x_i$ 是输入，$y_i$ 是输出标签

我们的目的是得到一个预测模型 $\hat{y} = f(x;\theta)$ , 其中 $\theta$ 表示模型的参数，$x$ 为输入同时 $\hat{y}$ 是预测的输出

优化的形式为：
$$
\theta^*=\arg \min_{\theta} \mathcal{L}(D;\theta,\omega)
$$
 其中的 $\omega$ 就是元知识，包括：

- 优化器类型
- 模型结构
- 模型参数的初始分布
- ...



我们会对已有的数据集 $D$ 进行任务划分，切分成多个任务集合，每一个任务集合包括一个训练集合以及一个测试集合，其形式为：
$$
D_{source} = \{(D^{train}_{source},D^{val}_{source})^{(i)}\}_{i=1}^{M}
$$
优化目标为:
$$
\omega^* = \arg \max_{\omega} \log p(\omega|D_{source})
$$
也就是在我们切分的多个任务集合中，找到一组配置（也就是元知识），使其对于这些任务来说最优。

一般称这个步骤为**元训练(meta-training)**

找到 $\omega^*$ 之后，便可以应用到一个目标任务数据集 $D_{target} = \{(D_{target}^{train}, D_{target}^{val})\}$

在这上面进行传统的训练，也就是找到一个最优的模型参数 $\theta^*$
$$
\theta^* = \arg\max_{\theta}\log p(\theta|\omega^*, D_{target}^{train})
$$
这个步骤称之为**元测试(meta-testing)**















